import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from tensorflow.keras import layers
import tensorflow_model_optimization as tfmot

# 参数设置
data_dir = "data/" 
batch_size = 32
img_height = 100 
img_width = 100

# 加载完整数据集并自动划分
train_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="training",
    seed=42,
    image_size=(img_height, img_width),
    batch_size=batch_size,
)

test_ds = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="validation",
    seed=42,
    image_size=(img_height, img_width),
    batch_size=batch_size,
)

# 查看类别标签
class_names = train_ds.class_names  

# 数据预处理：保持FLOAT32并归一化到[0,1]
def normalize(image, label):
    image = tf.cast(image, tf.float32)
    image = (image / 255)   # 归一化到 [0,1]
    return image, label

def create_vgg16_base_model():
    # 加载预训练的VGG16模型，不包含顶部全连接层
    base_model = tf.keras.applications.VGG16(
        include_top=False,
        weights='imagenet',
        input_shape=(100, 100, 3)
    )
    
    # 冻结预训练层
    for layer in base_model.layers:
        layer.trainable = False
    
    # 创建新的Sequential模型并添加VGG16的层
    model = tf.keras.Sequential()
    
    # 添加输入层
    model.add(tf.keras.layers.InputLayer(input_shape=(100, 100, 3)))
    
    # 逐个添加VGG16的层
    for layer in base_model.layers:
        model.add(layer)
    
    # 添加自定义顶部层
    model.add(tf.keras.layers.GlobalAveragePooling2D())
    model.add(tf.keras.layers.Dense(256, activation='relu'))
    model.add(tf.keras.layers.Dropout(0.5))
    model.add(tf.keras.layers.Dense(3, activation='softmax'))
    
    return model

# 应用量化感知训练
quantize_model = tfmot.quantization.keras.quantize_model
base_model = create_vgg16_base_model()
qat_model = quantize_model(base_model)

# 编译和训练模型
qat_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# 应用预处理到训练集和测试集
train_ds_normalized = train_ds.map(normalize, num_parallel_calls=tf.data.AUTOTUNE)
test_ds_normalized = test_ds.map(normalize, num_parallel_calls=tf.data.AUTOTUNE)

# 配置性能优化
train_ds_normalized = train_ds_normalized.cache().prefetch(buffer_size=tf.data.AUTOTUNE)
test_ds_normalized = test_ds_normalized.cache().prefetch(buffer_size=tf.data.AUTOTUNE)

# 训练模型
history = qat_model.fit(train_ds_normalized, epochs=100, validation_data=test_ds_normalized)

# 评估模型
test_loss, test_acc = qat_model.evaluate(test_ds_normalized)
print(f"测试集准确率: {test_acc:.2%}")

# 代表数据集生成函数
def representative_dataset():
    for images, _ in test_ds_normalized.unbatch().batch(1).take(100):
        yield [images]

# 转换模型配置
converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8  # 输入类型为INT8
converter.inference_output_type = tf.int8  # 输出类型为INT8

# 执行转换
try:
    tflite_model = converter.convert()
    with open("vgg16_quantized_int8.tflite", "wb") as f:
        f.write(tflite_model)
    print("VGG16模型量化并保存成功！")
except Exception as e:
    print(f"转换失败: {str(e)}")
    raise

# 验证INT8模型
def validate_int8_model():
    interpreter = tf.lite.Interpreter(model_path="vgg16_quantized_int8.tflite")
    interpreter.allocate_tensors()
    
    # 获取输入和输出张量信息
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    # 准备INT8输入数据
    def prepare_int8_input(image):
        # 将[-1,1]范围的FLOAT32转换为[-128,127]的INT8
        image = (image + 1.0) * 127.5  # 转回[0,255]
        image = tf.clip_by_value(image, 0, 255)
        image = tf.cast(image, tf.int8)
        return image
    
    # 评估模型
    all_predictions = []
    all_labels = []
    
    for image_batch, label_batch in test_ds_normalized:
        for i in range(image_batch.shape[0]):
            # 准备INT8输入
            input_data = prepare_int8_input(image_batch[i])
            input_data = tf.expand_dims(input_data, axis=0)
            
            # 设置输入
            interpreter.set_tensor(input_details[0]['index'], input_data)
            
            # 执行推理
            interpreter.invoke()
            
            # 获取INT8输出
            output_data = interpreter.get_tensor(output_details[0]['index'])
            
            # 反量化为浮点概率
            scale, zero_point = output_details[0]['quantization']
            probabilities = (output_data.astype(np.float32) - zero_point) * scale
            
            # 记录预测结果和真实标签
            all_predictions.append(np.argmax(probabilities))
            all_labels.append(label_batch[i].numpy())
    
    # 计算准确率
    accuracy = np.mean(np.array(all_predictions) == np.array(all_labels))
    print(f"VGG16 INT8模型准确率: {accuracy * 100:.2f}%")
    
    return accuracy

# 运行验证
validate_int8_model()
